{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a standard classification problem.\n",
    "#out of lot of classifiers I have used Logistic Regression, Decision Tree and experimented with MLP Neural Network classifier.\n",
    "\n",
    "#Assumptions: Red and White are replaced in the dataset preprocessing as 1 and 2 respectively.\n",
    "#Acuracy Scores : ~52% using Logistic Regression, ~60% using Decision Tree and <50% using Neural Network.(Which needs improvement by fine tuning the model)\n",
    "\n",
    "#NOTE: These models can be improved and fine tuned given time and expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 13)\n",
      "['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar', 'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality', 'style']\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('wine_dataset.csv', header=0)\n",
    "data = data.dropna()\n",
    "print(data.shape)\n",
    "print(list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'red': 1, 'white': 2}\n",
    "data = data.replace({'style': mapping})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed_acidity  volatile_acidity  citric_acid  residual_sugar  chlorides  \\\n",
      "3731            7.1             0.220         0.32           16.90      0.056   \n",
      "1651            6.2             0.160         0.33            1.10      0.057   \n",
      "5060            6.7             0.240         0.30            3.85      0.042   \n",
      "1303            8.0             0.280         0.44            1.80      0.081   \n",
      "474            10.5             0.280         0.51            1.70      0.080   \n",
      "4304            6.7             0.260         0.39            6.40      0.171   \n",
      "2731            6.8             0.390         0.31           14.35      0.043   \n",
      "1855            6.3             0.350         0.30            5.70      0.035   \n",
      "2752            5.3             0.395         0.07            1.30      0.035   \n",
      "5137            6.5             0.280         0.25            4.80      0.029   \n",
      "567             8.7             0.700         0.24            2.50      0.226   \n",
      "1949            6.3             0.120         0.36            2.10      0.044   \n",
      "2267            6.1             0.140         0.25            1.30      0.047   \n",
      "4053            7.1             0.290         0.30           16.00      0.036   \n",
      "2089            7.0             0.280         0.36            1.00      0.035   \n",
      "5776            6.4             0.250         0.33            1.70      0.037   \n",
      "6320            6.1             0.320         0.33           10.70      0.036   \n",
      "3900            6.6             0.220         0.28           12.05      0.058   \n",
      "1979            7.3             0.200         0.44            1.40      0.045   \n",
      "4205            7.2             0.200         0.36            2.50      0.028   \n",
      "666             8.3             0.490         0.36            1.80      0.222   \n",
      "3655            6.8             0.210         0.27           18.15      0.042   \n",
      "5656            6.6             0.170         0.36            1.90      0.036   \n",
      "3943            7.0             0.230         0.26            7.20      0.041   \n",
      "2126            6.1             0.280         0.22            1.80      0.034   \n",
      "6256            6.0             0.290         0.41           10.80      0.048   \n",
      "4663            7.4             0.210         0.80           12.30      0.038   \n",
      "5064            6.8             0.190         0.34            1.90      0.040   \n",
      "5329            6.2             0.220         0.20           20.80      0.035   \n",
      "2527            6.5             0.250         0.35           12.00      0.055   \n",
      "...             ...               ...          ...             ...        ...   \n",
      "99              8.1             0.545         0.18            1.90      0.080   \n",
      "2496            7.0             0.290         0.26            1.60      0.044   \n",
      "1871            5.8             0.250         0.26           13.10      0.051   \n",
      "2046            6.5             0.410         0.24           14.00      0.048   \n",
      "4851            7.1             0.260         0.37            5.50      0.025   \n",
      "5072            6.5             0.300         0.27            4.00      0.038   \n",
      "2163            6.8             0.510         0.30            4.20      0.066   \n",
      "6036            6.5             0.290         0.30            9.15      0.051   \n",
      "6216            5.2             0.500         0.18            2.00      0.036   \n",
      "2893            6.9             0.410         0.22            4.20      0.031   \n",
      "537             8.1             0.825         0.24            2.10      0.084   \n",
      "1701            6.0             0.210         0.24           12.10      0.050   \n",
      "2897            7.3             0.340         0.39            5.20      0.040   \n",
      "2222            7.2             0.240         0.34            1.10      0.045   \n",
      "2135            7.9             0.345         0.51           15.30      0.047   \n",
      "2599            8.0             0.190         0.36            1.80      0.050   \n",
      "705             8.4             1.035         0.15            6.00      0.073   \n",
      "6458            6.0             0.430         0.34            7.60      0.045   \n",
      "3468            8.2             0.180         0.28            8.50      0.035   \n",
      "5924            6.4             0.240         0.26            8.20      0.054   \n",
      "5874            5.7             0.220         0.20           16.00      0.044   \n",
      "4373            7.0             0.360         0.32           10.05      0.045   \n",
      "1033            7.5             0.570         0.08            2.60      0.089   \n",
      "5827            6.2             0.290         0.23           12.40      0.048   \n",
      "4859            7.4             0.190         0.31           14.50      0.045   \n",
      "4931            6.5             0.220         0.28            3.70      0.059   \n",
      "3264            6.5             0.130         0.37            1.00      0.036   \n",
      "1653            6.8             0.200         0.59            0.90      0.147   \n",
      "2607            6.6             0.220         0.37            1.20      0.059   \n",
      "2732            8.7             0.220         0.42            2.30      0.053   \n",
      "\n",
      "      free_sulfur_dioxide  total_sulfur_dioxide  density    pH  sulphates  \\\n",
      "3731                 49.0                 158.0  0.99980  3.37       0.38   \n",
      "1651                 21.0                  82.0  0.99100  3.32       0.46   \n",
      "5060                105.0                 179.0  0.99189  3.04       0.59   \n",
      "1303                 28.0                  68.0  0.99501  3.36       0.66   \n",
      "474                  10.0                  24.0  0.99820  3.20       0.89   \n",
      "4304                 64.0                 200.0  0.99562  3.19       0.38   \n",
      "2731                 28.0                 162.0  0.99880  3.17       0.54   \n",
      "1855                  8.0                  97.0  0.99270  3.27       0.41   \n",
      "2752                 26.0                 102.0  0.99200  3.50       0.35   \n",
      "5137                 54.0                 128.0  0.99074  3.17       0.44   \n",
      "567                   5.0                  15.0  0.99910  3.32       0.60   \n",
      "1949                 47.0                 146.0  0.99140  3.27       0.74   \n",
      "2267                 37.0                 173.0  0.99250  3.35       0.46   \n",
      "4053                 58.0                 201.0  0.99954  3.30       0.67   \n",
      "2089                  8.0                  70.0  0.98990  3.09       0.46   \n",
      "5776                 35.0                 113.0  0.99164  3.23       0.66   \n",
      "6320                 27.0                  98.0  0.99521  3.34       0.52   \n",
      "3900                 25.0                 125.0  0.99856  3.45       0.45   \n",
      "1979                 21.0                  98.0  0.99240  3.15       0.46   \n",
      "4205                 22.0                 157.0  0.99380  3.48       0.49   \n",
      "666                   6.0                  16.0  0.99800  3.18       0.60   \n",
      "3655                 41.0                 146.0  1.00010  3.30       0.36   \n",
      "5656                 38.0                 110.0  0.99056  3.05       0.54   \n",
      "3943                 21.0                  90.0  0.99509  3.22       0.55   \n",
      "2126                 32.0                 116.0  0.98980  3.36       0.44   \n",
      "6256                 55.0                 149.0  0.99370  3.09       0.59   \n",
      "4663                 77.0                 183.0  0.99778  2.95       0.48   \n",
      "5064                 41.0                 108.0  0.99000  3.25       0.45   \n",
      "5329                 58.0                 184.0  1.00022  3.11       0.53   \n",
      "2527                 47.0                 179.0  0.99800  3.58       0.47   \n",
      "...                   ...                   ...      ...   ...        ...   \n",
      "99                   13.0                  35.0  0.99720  3.30       0.59   \n",
      "2496                 12.0                  87.0  0.99230  3.08       0.46   \n",
      "1871                 44.0                 148.0  0.99720  3.29       0.38   \n",
      "2046                 24.0                 113.0  0.99820  3.44       0.53   \n",
      "4851                 31.0                 105.0  0.99082  3.06       0.33   \n",
      "5072                 37.0                  97.0  0.99026  3.20       0.60   \n",
      "2163                 38.0                 165.0  0.99450  3.20       0.42   \n",
      "6036                 25.0                 166.0  0.99339  3.24       0.56   \n",
      "6216                 23.0                 129.0  0.98949  3.36       0.77   \n",
      "2893                 10.0                 102.0  0.99300  3.00       0.86   \n",
      "537                   5.0                  13.0  0.99720  3.37       0.77   \n",
      "1701                 55.0                 164.0  0.99700  3.34       0.39   \n",
      "2897                 45.0                 163.0  0.99250  3.30       0.47   \n",
      "2222                  3.0                  64.0  0.99130  3.23       0.51   \n",
      "2135                 54.0                 171.0  0.99870  3.09       0.51   \n",
      "2599                 16.0                  84.0  0.99360  3.15       0.45   \n",
      "705                  11.0                  54.0  0.99900  3.37       0.49   \n",
      "6458                 25.0                 118.0  0.99222  3.03       0.37   \n",
      "3468                 41.0                 140.0  0.99520  3.04       0.37   \n",
      "5924                 47.0                 182.0  0.99538  3.12       0.50   \n",
      "5874                 41.0                 113.0  0.99862  3.22       0.46   \n",
      "4373                 37.0                 131.0  0.99352  3.09       0.33   \n",
      "1033                 14.0                  27.0  0.99592  3.30       0.59   \n",
      "5827                 33.0                 201.0  0.99612  3.11       0.56   \n",
      "4859                 39.0                 193.0  0.99860  3.10       0.50   \n",
      "4931                 29.0                 151.0  0.99177  3.23       0.41   \n",
      "3264                 48.0                 114.0  0.99110  3.41       0.51   \n",
      "1653                 38.0                 132.0  0.99300  3.05       0.38   \n",
      "2607                 45.0                 199.0  0.99300  3.37       0.55   \n",
      "2732                 27.0                 114.0  0.99400  2.99       0.43   \n",
      "\n",
      "      alcohol  style  \n",
      "3731     9.60      2  \n",
      "1651    10.90      2  \n",
      "5060    11.30      2  \n",
      "1303    11.20      1  \n",
      "474      9.40      1  \n",
      "4304     9.40      2  \n",
      "2731     9.10      2  \n",
      "1855    11.00      2  \n",
      "2752    10.60      2  \n",
      "5137    12.20      2  \n",
      "567      9.00      1  \n",
      "1949    11.40      2  \n",
      "2267    10.00      2  \n",
      "4053     9.00      2  \n",
      "2089    12.10      2  \n",
      "5776    10.60      2  \n",
      "6320    10.20      2  \n",
      "3900     9.40      2  \n",
      "1979    10.00      2  \n",
      "4205    10.60      2  \n",
      "666      9.50      1  \n",
      "3655     8.70      2  \n",
      "5656    11.40      2  \n",
      "3943     9.50      2  \n",
      "2126    12.60      2  \n",
      "6256    11.00      2  \n",
      "4663     9.00      2  \n",
      "5064    12.90      2  \n",
      "5329     9.00      2  \n",
      "2527    10.00      2  \n",
      "...       ...    ...  \n",
      "99       9.00      1  \n",
      "2496    10.50      2  \n",
      "1871     9.30      2  \n",
      "2046     9.80      2  \n",
      "4851    12.60      2  \n",
      "5072    12.60      2  \n",
      "2163     9.10      2  \n",
      "6036    11.35      2  \n",
      "6216    13.40      2  \n",
      "2893    11.60      2  \n",
      "537     10.70      1  \n",
      "1701     9.40      2  \n",
      "2897    12.40      2  \n",
      "2222    11.40      2  \n",
      "2135     9.10      2  \n",
      "2599     9.80      2  \n",
      "705      9.90      1  \n",
      "6458    11.00      2  \n",
      "3468    10.10      2  \n",
      "5924     9.50      2  \n",
      "5874     8.90      2  \n",
      "4373    11.70      2  \n",
      "1033    10.40      1  \n",
      "5827     9.90      2  \n",
      "4859     9.20      2  \n",
      "4931    12.10      2  \n",
      "3264    11.50      2  \n",
      "1653     9.10      2  \n",
      "2607    10.30      2  \n",
      "2732    10.00      2  \n",
      "\n",
      "[4872 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('quality', axis=1)\n",
    "y = data.quality\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731    6\n",
      "1651    7\n",
      "5060    8\n",
      "1303    5\n",
      "474     6\n",
      "4304    6\n",
      "2731    5\n",
      "1855    7\n",
      "2752    6\n",
      "5137    7\n",
      "567     6\n",
      "1949    7\n",
      "2267    6\n",
      "4053    5\n",
      "2089    6\n",
      "5776    6\n",
      "6320    6\n",
      "3900    5\n",
      "1979    7\n",
      "4205    6\n",
      "666     6\n",
      "3655    5\n",
      "5656    6\n",
      "3943    6\n",
      "2126    6\n",
      "6256    7\n",
      "4663    5\n",
      "5064    6\n",
      "5329    6\n",
      "2527    5\n",
      "       ..\n",
      "99      6\n",
      "2496    6\n",
      "1871    5\n",
      "2046    6\n",
      "4851    8\n",
      "5072    8\n",
      "2163    5\n",
      "6036    6\n",
      "6216    7\n",
      "2893    4\n",
      "537     6\n",
      "1701    5\n",
      "2897    6\n",
      "2222    5\n",
      "2135    5\n",
      "2599    7\n",
      "705     5\n",
      "6458    6\n",
      "3468    7\n",
      "5924    5\n",
      "5874    6\n",
      "4373    8\n",
      "1033    6\n",
      "5827    6\n",
      "4859    6\n",
      "4931    7\n",
      "3264    8\n",
      "1653    6\n",
      "2607    7\n",
      "2732    5\n",
      "Name: quality, Length: 4872, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4872, 12)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   6   4   0   0   0]\n",
      " [  0   0  39  16   0   0   0]\n",
      " [  0   0 296 235   1   0   0]\n",
      " [  0   0 175 521   8   0   0]\n",
      " [  0   0  20 242  12   0   0]\n",
      " [  0   0   2  44   1   0   0]\n",
      " [  0   0   0   3   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.51\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.00      0.00      0.00        55\n",
      "          5       0.55      0.56      0.55       532\n",
      "          6       0.49      0.74      0.59       704\n",
      "          7       0.55      0.04      0.08       274\n",
      "          8       0.00      0.00      0.00        47\n",
      "          9       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.48      0.51      0.45      1625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bkdas/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The confidence score:\n",
      "\n",
      "0.5963076923076923\n"
     ]
    }
   ],
   "source": [
    "prediction = clf.score(X_test, y_test)\n",
    "print(\"\\nThe confidence score:\\n\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The prediction:\n",
      "\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "8\n",
      "\n",
      "The expectation:\n",
      "\n",
      "5316    6\n",
      "5210    6\n",
      "3518    6\n",
      "1622    5\n",
      "2443    8\n",
      "Name: quality, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#converting the numpy array to list\n",
    "j=np.array(y_pred).tolist()\n",
    "\n",
    "#printing first 5 predictions\n",
    "print(\"\\nThe prediction:\\n\")\n",
    "for i in range(0,5):\n",
    "    print(j[i])\n",
    "    \n",
    "#printing first five expectations\n",
    "print(\"\\nThe expectation:\\n\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='lbfgs', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predictions = clf_mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 6 5 ... 6 6 6]\n"
     ]
    }
   ],
   "source": [
    "print(nn_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.00      0.00      0.00        10\n",
      "          4       0.00      0.00      0.00        55\n",
      "          5       0.48      0.32      0.38       532\n",
      "          6       0.45      0.72      0.55       704\n",
      "          7       0.40      0.20      0.27       274\n",
      "          8       0.00      0.00      0.00        47\n",
      "          9       0.00      0.00      0.00         3\n",
      "\n",
      "avg / total       0.42      0.45      0.41      1625\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bkdas/anaconda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,nn_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
